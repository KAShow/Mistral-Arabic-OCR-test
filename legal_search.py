#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… ÙÙ‡Ø±Ø³Ø© ÙˆØ¨Ø­Ø« Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†ÙŠØ©
Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SQLite Ù…Ø¹ Full-Text Search (FTS5)
"""

import sqlite3
import re
import os
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import json

@dataclass
class LegalArticle:
    """ÙƒÙ„Ø§Ø³ Ù„ØªÙ…Ø«ÙŠÙ„ Ù…Ø§Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
    id: int
    document_name: str
    page_number: int
    chapter: str
    section: str
    article_number: str
    title: str
    content: str
    article_type: str  # 'article', 'definition', 'general'

class LegalSearchEngine:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
    
    def __init__(self, db_path: str = "legal_database.db"):
        self.db_path = db_path
        self.conn = None
        self._init_database()
    
    def _init_database(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
        self.conn.execute('''
        CREATE TABLE IF NOT EXISTS documents (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL UNIQUE,
            title TEXT,
            file_path TEXT,
            pages_count INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        self.conn.execute('''
        CREATE TABLE IF NOT EXISTS articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            document_id INTEGER,
            page_number INTEGER,
            chapter TEXT,
            section TEXT,
            article_number TEXT,
            title TEXT,
            content TEXT,
            article_type TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (document_id) REFERENCES documents (id)
        )
        ''')
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ FTS5 Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹
        self.conn.execute('''
        CREATE VIRTUAL TABLE IF NOT EXISTS articles_fts USING fts5(
            article_id,
            document_name,
            chapter,
            section,
            article_number,
            title,
            content,
            content=articles,
            content_rowid=id
        )
        ''')
        
        # Ø¥Ù†Ø´Ø§Ø¡ triggers Ù„Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø¬Ø¯ÙˆÙ„ FTS
        self.conn.execute('''
        CREATE TRIGGER IF NOT EXISTS articles_ai AFTER INSERT ON articles BEGIN
            INSERT INTO articles_fts(article_id, document_name, chapter, section, article_number, title, content)
            VALUES (new.id, (SELECT name FROM documents WHERE id = new.document_id), 
                   new.chapter, new.section, new.article_number, new.title, new.content);
        END
        ''')
        
        self.conn.execute('''
        CREATE TRIGGER IF NOT EXISTS articles_ad AFTER DELETE ON articles BEGIN
            DELETE FROM articles_fts WHERE article_id = old.id;
        END
        ''')
        
        self.conn.execute('''
        CREATE TRIGGER IF NOT EXISTS articles_au AFTER UPDATE ON articles BEGIN
            DELETE FROM articles_fts WHERE article_id = old.id;
            INSERT INTO articles_fts(article_id, document_name, chapter, section, article_number, title, content)
            VALUES (new.id, (SELECT name FROM documents WHERE id = new.document_id), 
                   new.chapter, new.section, new.article_number, new.title, new.content);
        END
        ''')
        
        self.conn.commit()
        print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")

    def parse_markdown_document(self, file_path: str, document_name: str) -> List[LegalArticle]:
        """ØªØ­Ù„ÙŠÙ„ ÙˆØ«ÙŠÙ‚Ø© Markdown ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
        articles = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø¨ Ø§Ù„ØµÙØ­Ø§Øª
        pages = re.split(r'^## Page (\d+)', content, flags=re.MULTILINE)
        
        current_chapter = ""
        current_section = ""
        article_id = 0
        
        for i in range(1, len(pages), 2):
            page_num = int(pages[i])
            page_content = pages[i + 1].strip()
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø©
            lines = page_content.split('\n')
            current_article_content = []
            current_article_number = ""
            current_article_title = ""
            in_article = False
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¨Ø§Ø¨
                if line.startswith('Ø§Ù„Ø¨Ø§Ø¨'):
                    current_chapter = line
                    continue
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØµÙ„
                if line.startswith('Ø§Ù„ÙØµÙ„'):
                    current_section = line
                    continue
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø§Ø¯Ø©
                article_match = re.match(r'^(?:\*\*)?Ø§Ù„Ù…Ø§Ø¯Ø© \(([^)]+)\)(?:\*\*)?', line)
                if article_match:
                    # Ø­ÙØ¸ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
                    if in_article and current_article_content:
                        article_id += 1
                        articles.append(LegalArticle(
                            id=article_id,
                            document_name=document_name,
                            page_number=page_num,
                            chapter=current_chapter,
                            section=current_section,
                            article_number=current_article_number,
                            title=current_article_title,
                            content='\n'.join(current_article_content),
                            article_type='article'
                        ))
                    
                    # Ø¨Ø¯Ø§ÙŠØ© Ù…Ø§Ø¯Ø© Ø¬Ø¯ÙŠØ¯Ø©
                    current_article_number = article_match.group(1)
                    current_article_title = ""
                    current_article_content = []
                    in_article = True
                    continue
                
                # Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø§Ø¯Ø©
                if in_article:
                    current_article_content.append(line)
                else:
                    # Ù…Ø­ØªÙˆÙ‰ Ø¹Ø§Ù… (Ù…Ù‚Ø¯Ù…Ø©ØŒ Ø®Ø§ØªÙ…Ø©ØŒ Ø¥Ù„Ø®)
                    if line and len(line) > 10:
                        article_id += 1
                        articles.append(LegalArticle(
                            id=article_id,
                            document_name=document_name,
                            page_number=page_num,
                            chapter=current_chapter,
                            section=current_section,
                            article_number="",
                            title="",
                            content=line,
                            article_type='general'
                        ))
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙÙŠ Ø§Ù„ØµÙØ­Ø©
            if in_article and current_article_content:
                article_id += 1
                articles.append(LegalArticle(
                    id=article_id,
                    document_name=document_name,
                    page_number=page_num,
                    chapter=current_chapter,
                    section=current_section,
                    article_number=current_article_number,
                    title=current_article_title,
                    content='\n'.join(current_article_content),
                    article_type='article'
                ))
        
        print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(articles)} Ø¹Ù†ØµØ± Ù…Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©")
        return articles

    def index_document(self, file_path: str, document_name: str, title: str = ""):
        """ÙÙ‡Ø±Ø³Ø© ÙˆØ«ÙŠÙ‚Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©
        cursor = self.conn.execute('''
        INSERT OR REPLACE INTO documents (name, title, file_path, pages_count)
        VALUES (?, ?, ?, ?)
        ''', (document_name, title, file_path, 0))
        
        document_id = cursor.lastrowid
        
        # Ø­Ø°Ù Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        self.conn.execute('DELETE FROM articles WHERE document_id = ?', (document_id,))
        
        # ØªØ­Ù„ÙŠÙ„ ÙˆÙÙ‡Ø±Ø³Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        articles = self.parse_markdown_document(file_path, document_name)
        
        # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        for article in articles:
            self.conn.execute('''
            INSERT INTO articles 
            (document_id, page_number, chapter, section, article_number, title, content, article_type)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                document_id, article.page_number, article.chapter, article.section,
                article.article_number, article.title, article.content, article.article_type
            ))
        
        # ØªØ­Ø¯ÙŠØ« Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª
        max_page = max([a.page_number for a in articles]) if articles else 0
        self.conn.execute('UPDATE documents SET pages_count = ? WHERE id = ?', (max_page, document_id))
        
        self.conn.commit()
        print(f"âœ… ØªÙ… ÙÙ‡Ø±Ø³Ø© Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© '{document_name}' Ø¨Ù†Ø¬Ø§Ø­!")
        return len(articles)

    def search(self, query: str, limit: int = 10) -> List[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙÙ‡Ø±Ø³"""
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
        clean_query = query.strip()
        if not clean_query:
            return []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… FTS5
        cursor = self.conn.execute('''
        SELECT 
            a.id,
            a.document_id,
            d.name as document_name,
            d.title as document_title,
            a.page_number,
            a.chapter,
            a.section,
            a.article_number,
            a.title,
            a.content,
            a.article_type,
            articles_fts.rank
        FROM articles_fts 
        JOIN articles a ON articles_fts.rowid = a.id
        JOIN documents d ON a.document_id = d.id
        WHERE articles_fts MATCH ?
        ORDER BY articles_fts.rank
        LIMIT ?
        ''', (clean_query, limit))
        
        results = []
        for row in cursor.fetchall():
            result = dict(row)
            # ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚
            result['highlighted_content'] = self._highlight_matches(result['content'], clean_query)
            results.append(result)
        
        return results

    def _highlight_matches(self, text: str, query: str) -> str:
        """ØªÙ…ÙŠÙŠØ² Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ Ø§Ù„Ù†Øµ"""
        words = query.split()
        highlighted_text = text
        
        for word in words:
            if len(word) > 2:  # ØªØ¬Ù†Ø¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                pattern = re.compile(re.escape(word), re.IGNORECASE)
                highlighted_text = pattern.sub(f'**{word}**', highlighted_text)
        
        return highlighted_text

    def get_article_by_number(self, article_number: str, document_name: str = None) -> Optional[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø§Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø±Ù‚Ù…Ù‡Ø§"""
        query = '''
        SELECT 
            a.id, d.name as document_name, d.title as document_title,
            a.page_number, a.chapter, a.section, a.article_number,
            a.title, a.content, a.article_type
        FROM articles a
        JOIN documents d ON a.document_id = d.id
        WHERE a.article_number = ?
        '''
        params = [article_number]
        
        if document_name:
            query += ' AND d.name = ?'
            params.append(document_name)
        
        cursor = self.conn.execute(query, params)
        row = cursor.fetchone()
        
        return dict(row) if row else None

    def get_statistics(self) -> Dict:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        stats = {}
        
        # Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
        cursor = self.conn.execute('SELECT COUNT(*) FROM documents')
        stats['documents_count'] = cursor.fetchone()[0]
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯
        cursor = self.conn.execute('SELECT COUNT(*) FROM articles')
        stats['articles_count'] = cursor.fetchone()[0]
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        cursor = self.conn.execute('''
        SELECT article_type, COUNT(*) 
        FROM articles 
        GROUP BY article_type
        ''')
        stats['articles_by_type'] = dict(cursor.fetchall())
        
        return stats

    def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if self.conn:
            self.conn.close()

def main():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…"""
    print("ğŸ” Ù†Ø¸Ø§Ù… ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†ÙŠØ©")
    print("=" * 50)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø«
    engine = LegalSearchEngine()
    
    # ÙÙ‡Ø±Ø³Ø© ÙˆØ«ÙŠÙ‚Ø© Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù…Ù„
    document_path = "docs_exports/document.md"
    if os.path.exists(document_path):
        engine.index_document(
            document_path, 
            "Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£Ù‡Ù„ÙŠ", 
            "Ù‚Ø§Ù†ÙˆÙ† Ø±Ù‚Ù… (36) Ù„Ø³Ù†Ø© 2012"
        )
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = engine.get_statistics()
        print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
        print(f"   ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: {stats['documents_count']}")
        print(f"   ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯: {stats['articles_count']}")
        print(f"   ğŸ“‹ ØªÙØµÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯: {stats['articles_by_type']}")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
        test_queries = [
            "Ø§Ù„Ø¹Ø§Ù…Ù„",
            "Ø§Ù„Ø£Ø¬Ø±",
            "ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„",
            "Ø¹Ù‚Ø¯ Ø§Ù„Ø¹Ù…Ù„"
        ]
        
        print(f"\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«:")
        for query in test_queries:
            results = engine.search(query, limit=3)
            print(f"\nğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: '{query}' - {len(results)} Ù†ØªÙŠØ¬Ø©")
            for result in results[:2]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ Ù†ØªÙŠØ¬ØªÙŠÙ†
                print(f"   ğŸ“„ Ø§Ù„Ù…Ø§Ø¯Ø© ({result['article_number']}) - Ø§Ù„ØµÙØ­Ø© {result['page_number']}")
                print(f"   ğŸ“ {result['content'][:100]}...")
    else:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©!")
    
    engine.close()

if __name__ == "__main__":
    main()
